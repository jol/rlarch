#!/usr/bin/env python

# going to explore installed packaged.
import os
import pkg_resources
import subprocess
import tempfile
import shutil
import sys
import fileinput
import struct

# should have a pacman.conf reader.
url_download = 'http://mir.archlinux.fr'

class EnvDir:
    """
    Just a container for directory variables.
    """
    def __init__(self, prefix):
        """
        Setup variables
        """
        self.prefix = prefix
        self.db_path   = os.path.join(self.prefix, 'var/lib/pacman')
        self.local_db  = os.path.join(self.db_path, 'local')
        self.sync_db   = os.path.join(self.db_path, 'sync')
        self.cache_dir = os.path.join(self.prefix, 'var/cache/pacman/pkg')

    def create(self):
        for p in (self.prefix, self.db_path, self.local_db, 
                  self.sync_db, self.cache_dir):
            if not os.path.exists(p): os.makedirs(p)


def _parse_package(fd):
    """
    Parse a package file descriptor. 
    @param fd:   the file descriptor from where we read data.
    @return map of category. Each category contains a vector.
    """
    result = {}
    current_cat = ''
    for line in fd.readlines():
        if '%' in line:
            current_cat = line[:-1].replace('%', '')
            continue
        if line == '\n': continue
        if current_cat != '':
                result.setdefault(current_cat, []).append(line[:-1])
    return result


def _read_database(db_name, incoming_db_filename):
    """
    Read a database.

    @return a map<package name, (version, depends, db_name)>.
    """
    import tarfile, zlib

    tar = tarfile.open(incoming_db_filename, 'r:gz')
    name = ''; version = ''
    result = {}
    for tarinfo in tar:
        # fetch version from directory.
        if tarinfo.isdir():
            name, version, revision = tarinfo.name.rsplit('-', 2)
            version = pkg_resources.parse_version(version + "-" + revision)
            
        # extract depends information.
        elif tarinfo.isfile():
            if "/depends" in tarinfo.name:
                depends = _parse_package(tar.extractfile(tarinfo))
                result[name] = (version, depends, db_name)
        
    return result

def _read_descs_from_db(packages, db_name, incoming_db_filename):
    """
    Read description for all packages from the database.
    We open the data using tar and we browse it.
    
    Once we found a requested package, we read the desc file.

    @param packages: a set of packages.
    @param dn_name: the name of the database.
    @param incoming_db_filename: the database filepath.

    @return a map<pkgname, (version, desc, db_name)>
    """
    import tarfile, zlib

    tar = tarfile.open(incoming_db_filename, 'r:gz')
    name = ''; version = ''
    result = {}
    for tarinfo in tar:
        # fetch version from directory.
        if tarinfo.isdir():
            name, version, revision = tarinfo.name.rsplit('-', 2)
            version = pkg_resources.parse_version(version + "-" + revision)
            continue
        
        # extract depends information.
        elif tarinfo.isfile():
            if name  not in packages: continue
            
            if "/desc" in tarinfo.name:
                desc = _parse_package(tar.extractfile(tarinfo))
                result[name] = (version, desc, db_name)
        
    return result




def read_installed_packages(env_dir):
    """
    @param local_db_path: the local db path.
    @return a map indexed by package name. Value
    are a tuple (version, revision, description_map)
    """
    # detect installed package.
    installed_db = {} # indexed by program name.
    for soft in os.listdir(env_dir.local_db):
        name, version, revision = soft.rsplit('-', 2)
        version = pkg_resources.parse_version(version + "-" + revision)
        # read depends.
        descr = os.path.join(env_dir.local_db,
                             soft, 'desc')
        descr = _parse_package(open(descr))
        installed_db[name] = (version, descr)
    
    return installed_db



def read_databases(databases, env_dir):
    """
    Read databases passed by parameter.
    
    @param databases: array of databases
    @param env_dir: variable with all available path.
    
    @return a map<pkg name, (version, depends, db_name)>
    """
    # read all databases defined in databases variable.
    db_packages = {}
    for db_name in databases:
        db_file = os.path.join(env_dir.sync_db, db_name + '.db')
        pkgs = _read_database(db_name, db_file)
        db_packages.update(pkgs)
        
    return db_packages



def read_descriptions(packages, databases, db_packages, env_dir):
    """
    Read all descriptions.
    """
    # group per database
    updates_per_db = {}
    for name in packages:
        pkg = db_packages[name]
        updates_per_db.setdefault(pkg[2], set()).add(name)

    # load descriptions.
    descriptions = {}
    for db_name in config.databases:

        pkgs = updates_per_db.get(db_name)
        if pkgs is None: continue
        
        db_file = os.path.join(env_dir.sync_db, db_name + '.db')
        pkgs = _read_descs_from_db(pkgs, db_name, db_file)
        descriptions.update(pkgs)

    return descriptions



def _order_packages_to_update(update_packages,
                              installed_packages,
                              db_packages,
                              already_scheduled = {}
                              ):
    """
    Order Packages in to a vector depends on
    their dependency, moreover, it will add required
    packages.
    """
    tmp = []
    for name in update_packages:

        # extract name.
        # ... TODO: do it better.
        if ">=" in name: name = name.split('>=')[0]
        if "==" in name: name = name.split('==')[0]
        
        # check if already scheduled
        if name in already_scheduled: continue
        
        # get depends
        db_pkg = db_packages.get(name)
        if db_pkg is None: continue
        
        deps = db_pkg[1].get('DEPENDS')
        if deps is None:
            tmp.append(name)
            already_scheduled[name] = 1
            continue
        
        # process dependencies.
        tmp += _order_packages_to_update(deps,
                                         installed_packages,
                                         db_packages,
                                         already_scheduled)

        # the current name
        if name in already_scheduled:
            print("strange: '%s' should not be already in the queue" % (name))
            continue

        
        # compare the version between installed 
        if name not in installed_packages or \
           db_packages[name][0] > installed_packages[name][0]:
            # append the current package.
            tmp.append(name)
            already_scheduled[name] = 1

    return tmp


def update_installed_package(installed_packages,
                             db_packages):
    """
    @return a tuple of (update or install pkgs, no present in db)
    """
    packages_to_update = []
    packages_missing = []
    for name, oldpkg in installed_packages.iteritems():
        # check if the package continue to exists.
        npkg = db_packages.get(name)
        if npkg is None:
            packages_missing.append(name)
        elif npkg[0] > oldpkg[0]:
            packages_to_update.append(name)

    # order packages.
    packages_to_update = _order_packages_to_update(packages_to_update,
                                                   installed_packages,
                                                   db_packages)
    return packages_to_update, packages_missing


def determine_package_to_update(packages, installed_packages, db_packages):
    """
    Determine which package to install based on their dependencies.
    @param packages: an of package name to install.
    @param installed_packages: packages already installed on the system.
    @param db_packages: available packages from db.
    """



def download_package(source, target, md5sum=None):

    #xfer_command = "/usr/bin/curl -C - -f %u > %o"
    # /usr/bin/wget --passive-ftp -c -O %o %u
    # download using curl.
    if os.path.exists(target) and md5sum:
        # on file exists, we check 
        output = subprocess.check_output(["md5sum", target])
        compute_md5sum = output.split(' ')[0]
    
        if md5sum == compute_md5sum:
            return 0
        print "wrong checksum, deleting file: ", target
        os.unlink(target)
    
    print "downloading: ", source, target    
    retcode = subprocess.call(["/usr/bin/wget", "-c", "-O", target, source ])
    

def download_databases(from_url, databases, env_dir):
    """
    Download databases to the directory.
    """
    # url: http://.../database/os/arch/database.db
    for db in databases:
        #TODO: python 3: os.uname().machine
        db_url = '%s/%s/os/%s/%s.db' % (from_url, db, os.uname()[4], db)
        db_target = '%s/%s.db' % (env_dir.sync_db, db)
        
        download_package(db_url, db_target)


def uncompress_archive(filename):
    """
    uncompress a xz archive into a directory.
    @param filename: the archive filename
    @output_dir: the output directory.
    @return the directory where the archive has been extracted.
    The caller has to remove the directory.
    """
    # create the temporary output directory.
    tmp_dir = tempfile.mkdtemp()

    shutil.copy(filename, tmp_dir)
    filename = os.path.join(tmp_dir, os.path.basename(filename))
    retcode  = subprocess.call(["xz", "-d", filename])
    filename = filename[:-3]
    retcode  = subprocess.call(["tar", "xf", filename, "-C", tmp_dir])
    os.unlink(filename)

    return tmp_dir


def _file_replace_inplace(filename, replaces):
    """
    Make a replace inplace in a file.
    @param filename: the filename that will be updated.
    @param search: the search pattern.
    @param replace: the replace Value
    @return the number of line changed.
    """
    count = 0
    for line in fileinput.input(filename, inplace=1):
        
        for r in replaces:
            if r[0] in line:
                line = line.replace(r[0], r[1])
                count += 1
        sys.stdout.write(line)
            
    return count



def _is_elf_file(filename):
    """
    Check if the file is an ELF file.
    """
    if os.path.getsize(filename) < 4: return False
    f = open(filename, 'rb')
    header = struct.unpack('4c', f.read(4))
    return ('\x7f', 'E', 'L', 'F') == header



def _list_elf_files(dirname):
    """
    List all elf file present in the hierarchy
    """
    def _over(arg, dirname, fnames):
        for f in fnames:
            p = os.path.join(dirname, f)
            if not os.path.isfile(p): continue
            if _is_elf_file(p):
                arg.append(p)
    tmp = []
    os.path.walk(dirname, _over, tmp)
    return tmp


def _patch_elf_file(filename, new_root_path, replaces):
    
    # TODO: we could put this stuff outside.
    mandatory_rpath = [os.path.join(new_root_path, p) for p in ['usr/lib', 'usr/local/lib', 'lib']]
    mandatory_rpath = ':'.join(mandatory_rpath)

    # get current rpath
    cmds = ["patchelf", "--print-rpath", filename]
    try:
        # get rpath and change it.
        rpath = subprocess.check_output(cmds)

        # we should add other rpath: /usr/lib:/usr/local/lib:/lib
        for r in replaces:
            rpath = rpath.replace(r[0], r[1])
        rpath = '%s:%s' % (rpath.replace('\n', ''), mandatory_rpath)

        # set rpath
        cmds = ["patchelf", "--set-rpath", rpath, filename]
        retcode = subprocess.call(cmds)

    except Exception, e:
        #if not rpath.startswith('cannot find'):
        #    print "failed to patch ELF file '%s'; error(%s)" % (filename, str(e))
        #    return False
        pass

    return True

def rewrite_path(package_dir, new_root_path):
    """
    @param package_dir: the package directory.
    @param new_root_path: the root path used to rewrite
    """
    # list of file that maybe rewritten.
    cmds = ["find",  package_dir, 
            "!", "-name", "*.h", 
            "!", "-name", ".html", 
            "!", "-name", "*.hpp",
            "-type", "f", 
            "-exec", "grep", "-Il", ".", "{}", ";"]
    outputs = subprocess.check_output(cmds)
    
    # use sed inplace to replace /usr by the new root path.
    to_replace = [
        ['/usr', os.path.join(new_root_path, 'usr')],
        ['/etc', os.path.join(new_root_path, 'etc')],
        ['/var', os.path.join(new_root_path, 'var')],   
    ]

    count_text_modified = 0
    for f in outputs[:-1].split('\n'):
        count = _file_replace_inplace(f, to_replace)
        if count: count_text_modified += 1
    #print "number of rewritten text file:", count_text_modified
    

    # now patch binary file, find all elf file inside
    # a directory. once found, execute the patchelf command
    elf_files = _list_elf_files(package_dir)
    for e in elf_files:
        _patch_elf_file(e, new_root_path, to_replace)

    return
    

def _merge_directory(source_dir, target_dir):
    """
    used to move the contents of source directory
    to the target directoy.
    """

    skip_files = [os.path.join(source_dir, x) for x in [
        'var/lock'
    ]]

    installed_files = []
    len_target_dir = len(target_dir) + 1
    for src_dir, dirs, files in os.walk(source_dir):
        dst_dir = src_dir.replace(source_dir, target_dir)
        
        if not os.path.exists(dst_dir):
            os.mkdir(dst_dir)
        for file_ in files:
        
            
            src_file = os.path.join(src_dir, file_)
            dst_file = os.path.join(dst_dir, file_)
            
            installed_files.append(dst_file[len_target_dir:])

            if os.path.exists(dst_file):
                os.remove(dst_file)
            
            if src_file in skip_files: continue
            try:
                shutil.copy2(src_file, dst_dir)
            except Exception, e:
                print "+++ failed to copy file: ", src_file
    
    return installed_files


def insert_to_local_db(package, version, descr,
                       depends, files, env_dir):
    # remove the directory if it does not exists.
    pkgver = "%s-%s" % (package, version)

    target_dir = os.path.join(env_dir.local_db, pkgver)
    if os.path.exists(target_dir):
        shutil.rmtree(target_dir)

    # create directory.
    os.makedirs(target_dir)

    descr.update(depends)

    # generate desc file.
    f = open(os.path.join(target_dir, 'desc'), 'w')
    for key, lines in descr.iteritems():
        f.write('%%%s%%\n' % (key))
        for line in lines:
            f.write(line + '\n')
    f.close()

    # write files
    f = open(os.path.join(target_dir, 'files'), 'w')
    for file in files:
        f.write(file + '\n')
    f.close()


def update_packages(packages, descriptions, 
                    installed_packages, db_packages, 
                    url, env_dir):


    for pkg in to_update:
        desc     = descriptions[pkg][1]
        filename = desc['FILENAME'][0]
        db_version = desc['VERSION'][0]

        db_name  = db_packages[pkg][2]
        db_depends = db_packages[pkg][1]
        

        md5sum_expected = desc['MD5SUM'][0]

        # build source & target.
        source_url =  '%s/%s/os/x86_64/%s' % (url, db_name, filename)
        target_url = '%s/%s' % (env_dir.cache_dir, filename)

        # download
        download_package(source_url, target_url, md5sum = md5sum_expected)

        # note we should check if md5sum are valid.

        # uncompress xz into temporary directory.
        tmp_dir = uncompress_archive(target_url)
        
        # rewrite rpath and other files.
        if pkg != 'glibc':
            rewrite_path(tmp_dir, env_dir.prefix)

        # uninstall previous package.
        if pkg in installed_packages:
            print "+++ we have to uninstall", pkg

        # copy file.
        installed_files = _merge_directory(tmp_dir, env_dir.prefix)

        # should destroy the temporary directory.

        # generate local save.
        insert_to_local_db(pkg, db_version, desc, db_depends,
                           installed_files, env_dir)


def params():
    import optparse

    parser = optparse.OptionParser()

    # --> Verbosity
    parser.add_option('-v', '--verbose',
                    action = 'store_true',
                    dest = 'verbose',
                    default = False,
                    help = 'enable verbose messages [default: %default]')

    parser.add_option('-E', '--env',
                       action= 'store',
                       dest='env',
                       default=os.environ.get('RLARCH_PREFIX'))

    parser.add_option('--create-env',
                       action='store_true',
                       dest='create_env',
                       default=False,
                       help= 'use this option to bootstrap an environnement.')

    parser.add_option('-S',
                       action='store_true',
                       dest='synchronize',
                       default = False,
                       help = 'Synchronize package.')

    parser.add_option('-y',
                       action='store_true',
                       dest='fetch_db',
                       default = False,
                       help = 'Update the database from the Official ArchLinux repository.')

    parser.add_option('-u',
                       action='store_true',
                       dest='upgrade',
                       default = False,
                       help = 'Upgrade packages of the system')

    parser.add_option('--from-url',
                       action = 'store',
                       dest='from_url',
                       default = 'http://mir.archlinux.fr',
                       help= 'The url used to download database and packages.')

    parser.add_option('--databases',
                      action='store',
                      dest='databases',
                      default='core,extra,community',
                      help='List of comma separated databases.')

    config, args = parser.parse_args()
    if config.databases:
        config.databases = config.databases.split(',')

    return config, args


if __name__ == '__main__':

    # create parser
    config, packages = params()

    # make sure that environnement is defined.
    if config.env is None:
        print "you have to define the prefix to use through the RLARCH_PREFIX variable or --env parameter."
        sys.exit(1)

    # make sure that the directory exists.
    # TODO: create a check env function that will ensure that basic requirements are present.
    if not os.path.exists(config.env):
        print "the environnement '%s' does not exist, you have to bootstrap it." % (config.env)
        sys.exit(1)

    env_dir = EnvDir(config.env)

    if config.create_env:
        env_dir.create()


    # synchronize stuff
    if config.synchronize:
        if config.fetch_db:
            # make sure that the target dictionary exists.
            print "going to synchronize database."
            download_databases(config.from_url, config.databases, env_dir)

        if config.upgrade:
            # list installed packages
            installed_packages = read_installed_packages(env_dir)
            print("nb installed packages: ", len(installed_packages))

            # read databases
            available_packages = read_databases(config.databases, env_dir)

            # determine which package to update.
            to_update, _ = update_installed_package(installed_packages,
                                                    available_packages)

            # prepare download.
        
        if len(packages):   
            # split packages and make an empty vertion.
            packages_to_install = {}
            for p in packages: 
                packages_to_install[p] = pkg_resources.parse_version('0.0.0')

            # read installed packages.
            installed_packages = read_installed_packages(env_dir)
            print("nb installed packages: ", len(installed_packages))

            # read databases
            print "reading databases:", config.databases
            db_packages = read_databases(config.databases, env_dir)


            # determine which package to update.
            to_update, _ = update_installed_package(packages_to_install,
                                                    installed_packages,
                                                    db_packages)


            print "reading description for: ", to_update
            descriptions = read_descriptions(to_update, config.databases,
                                             db_packages, env_dir)

            # update packages.
            update_packages(to_update, descriptions, 
                            installed_packages, db_packages,
                            config.from_url, env_dir)            


